% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/classification.R
\name{xgboostRF}
\alias{xgboostRF}
\title{xgboost random forests algorithm}
\usage{
xgboostRF(
  train.ds = NULL,
  holdout.ds = NULL,
  validation.ds = NULL,
  label = "class",
  method.model = "classification",
  cv.folds = NULL,
  num.threads = 2,
  num.rounds = c(1),
  max.depth = c(4),
  shrinkage = c(1),
  objective = "binary:logistic",
  save.file = NULL,
  verbose = FALSE
)
}
\arguments{
\item{train.ds}{A data frame with training data and outcome labels}

\item{holdout.ds}{A data frame with holdout data and outcome labels}

\item{validation.ds}{A data frame with validation data and outcome labels}

\item{label}{A character vector of the outcome variable column name}

\item{method.model}{A character vector of the response variable type for the model}

\item{cv.folds}{An integer for the number of cross validation folds}

\item{num.threads}{An integer for OpenMP number of cores}

\item{num.rounds}{An integer number of xgboost boosting iterations}

\item{max.depth}{An integer aximum tree depth}

\item{shrinkage}{A numeric gradient learning rate 0-1}

\item{objective}{A character vector for the name of the objective function in XGBoost}

\item{save.file}{A character vector for results filename or NULL to skip}

\item{verbose}{A flag indicating whether verbose output be sent to stdout}
}
\value{
A list containing:
\describe{
  \item{algo.acc}{data frame of results, a row for each update}
  \item{ggplot.data}{melted results data frame for plotting}
  \item{trn.model}{xgboost model}
  \item{elapsed}{total elapsed time}
}
}
\description{
Scalable and Flexible Gradient Boosting
XGBoost is short for “Extreme Gradient Boosting”, where the term “Gradient Boosting”
is proposed in the paper Greedy Function Approximation: A Gradient Boosting Machine,
by Friedman. XGBoost is based on this original model. This is a function using gradient
boosted trees for privacyEC.
}
\examples{
num.samples <- 100
num.variables <- 100
pct.signals <- 0.1
label <- "class"
sim.data <- createSimulation(num.variables = num.variables,
                             num.samples = num.samples,
                             pct.signals = pct.signals,
                             label = label,
                             sim.type = "mainEffect",
                             pct.train = 1 / 3,
                             pct.holdout = 1 / 3,
                             pct.validation = 1 / 3,
                             verbose = FALSE)
rra.results <- xgboostRF(train.ds = sim.data$train,
                         holdout.ds = sim.data$holdout,
                         validation.ds = sim.data$validation,
                         label = sim.data$label,
                         num.rounds = c(1),
                         max.depth = c(10),
                         verbose = FALSE)
}
\seealso{
Other classification: 
\code{\link{epistasisRank}()},
\code{\link{getImportanceScores}()},
\code{\link{originalThresholdout}()},
\code{\link{privateEC}()},
\code{\link{privateRF}()},
\code{\link{standardRF}()}
}
\concept{classification}
